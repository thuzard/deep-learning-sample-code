{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Standard Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Close_diff_y>     2228\n",
       "<Close_diff>       2228\n",
       "<Open_diff>        2228\n",
       "<High_diff>        2228\n",
       "<Low_diff>         2228\n",
       " <Volume>          2228\n",
       " <FastAvg_diff>    2228\n",
       " <MedAvg_diff>     2228\n",
       " <SlowAvg_diff>    2228\n",
       " <Red 5>           2228\n",
       " <Yellow 5>        2228\n",
       " <Blue 5>          2228\n",
       " <DBlue 5>         2228\n",
       " <Red 1>           2228\n",
       " <Yellow 1>        2228\n",
       " <Blue 1>          2228\n",
       " <DBlue 1>         2228\n",
       " <SlowK>           2228\n",
       " <SlowD>           2228\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CL_dnn_data.csv\")\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_plot = data.loc[:, [\"<Close_diff_y>\"]]\n",
    "data_to_plot = data_to_plot.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/UtzUKwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227b94aef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data_to_plot)\n",
    "plt.title(\"Close price differetial histogram\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.ylabel(\"times\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[0:2000]\n",
    "data_test = data.iloc[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = data_train.loc[:, [\"<Close_diff_y>\"]]\n",
    "x_train_raw = data_train.drop(\"<Close_diff_y>\", axis = 1)\n",
    "\n",
    "\n",
    "y_test = data_test.loc[:, [\"<Close_diff_y>\"]]\n",
    "x_test_raw = data_test.drop(\"<Close_diff_y>\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;Close_diff&gt;</th>\n",
       "      <th>&lt;Open_diff&gt;</th>\n",
       "      <th>&lt;High_diff&gt;</th>\n",
       "      <th>&lt;Low_diff&gt;</th>\n",
       "      <th>&lt;Volume&gt;</th>\n",
       "      <th>&lt;FastAvg_diff&gt;</th>\n",
       "      <th>&lt;MedAvg_diff&gt;</th>\n",
       "      <th>&lt;SlowAvg_diff&gt;</th>\n",
       "      <th>&lt;Red 5&gt;</th>\n",
       "      <th>&lt;Yellow 5&gt;</th>\n",
       "      <th>&lt;Blue 5&gt;</th>\n",
       "      <th>&lt;DBlue 5&gt;</th>\n",
       "      <th>&lt;Red 1&gt;</th>\n",
       "      <th>&lt;Yellow 1&gt;</th>\n",
       "      <th>&lt;Blue 1&gt;</th>\n",
       "      <th>&lt;DBlue 1&gt;</th>\n",
       "      <th>&lt;SlowK&gt;</th>\n",
       "      <th>&lt;SlowD&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00781</td>\n",
       "      <td>-0.009020</td>\n",
       "      <td>-0.008930</td>\n",
       "      <td>-0.007760</td>\n",
       "      <td>2.428458e+05</td>\n",
       "      <td>-0.009350</td>\n",
       "      <td>-0.009670</td>\n",
       "      <td>-0.010445</td>\n",
       "      <td>-0.057720</td>\n",
       "      <td>-0.195240</td>\n",
       "      <td>-0.469265</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>-0.025220</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>51.594990</td>\n",
       "      <td>51.572320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.39912</td>\n",
       "      <td>1.395431</td>\n",
       "      <td>1.162925</td>\n",
       "      <td>1.239757</td>\n",
       "      <td>1.189469e+05</td>\n",
       "      <td>0.678188</td>\n",
       "      <td>0.454326</td>\n",
       "      <td>0.322362</td>\n",
       "      <td>2.100776</td>\n",
       "      <td>5.273686</td>\n",
       "      <td>9.576264</td>\n",
       "      <td>4.601332</td>\n",
       "      <td>0.960603</td>\n",
       "      <td>2.270821</td>\n",
       "      <td>3.854396</td>\n",
       "      <td>2.197141</td>\n",
       "      <td>29.188785</td>\n",
       "      <td>28.361945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.97000</td>\n",
       "      <td>-9.020000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-10.230000</td>\n",
       "      <td>6.339000e+03</td>\n",
       "      <td>-3.730000</td>\n",
       "      <td>-2.010000</td>\n",
       "      <td>-1.170000</td>\n",
       "      <td>-6.780000</td>\n",
       "      <td>-12.670000</td>\n",
       "      <td>-22.460000</td>\n",
       "      <td>-15.400000</td>\n",
       "      <td>-4.060000</td>\n",
       "      <td>-7.840000</td>\n",
       "      <td>-12.680000</td>\n",
       "      <td>-10.240000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>2.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.87000</td>\n",
       "      <td>-0.870000</td>\n",
       "      <td>-0.670000</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>1.657750e+05</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-1.480000</td>\n",
       "      <td>-3.762500</td>\n",
       "      <td>-6.852500</td>\n",
       "      <td>-2.862500</td>\n",
       "      <td>-0.570000</td>\n",
       "      <td>-1.322500</td>\n",
       "      <td>-2.480000</td>\n",
       "      <td>-1.210000</td>\n",
       "      <td>23.612500</td>\n",
       "      <td>24.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>2.184665e+05</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.320000</td>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.855000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.110000</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>53.930000</td>\n",
       "      <td>53.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.85250</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.911875e+05</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>2.932500</td>\n",
       "      <td>4.762500</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>2.182500</td>\n",
       "      <td>1.252500</td>\n",
       "      <td>78.162500</td>\n",
       "      <td>77.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.41000</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>4.510000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>1.075988e+06</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>19.070000</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>5.310000</td>\n",
       "      <td>9.490000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>8.360000</td>\n",
       "      <td>99.050000</td>\n",
       "      <td>98.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       <Close_diff>  <Open_diff>  <High_diff>   <Low_diff>      <Volume>  \\\n",
       "count    2000.00000  2000.000000  2000.000000  2000.000000  2.000000e+03   \n",
       "mean       -0.00781    -0.009020    -0.008930    -0.007760  2.428458e+05   \n",
       "std         1.39912     1.395431     1.162925     1.239757  1.189469e+05   \n",
       "min        -8.97000    -9.020000    -7.000000   -10.230000  6.339000e+03   \n",
       "25%        -0.87000    -0.870000    -0.670000    -0.680000  1.657750e+05   \n",
       "50%         0.01000     0.010000    -0.050000     0.060000  2.184665e+05   \n",
       "75%         0.85250     0.832500     0.630000     0.700000  2.911875e+05   \n",
       "max         6.41000     6.420000     4.510000     4.760000  1.075988e+06   \n",
       "\n",
       "        <FastAvg_diff>   <MedAvg_diff>   <SlowAvg_diff>      <Red 5>  \\\n",
       "count      2000.000000     2000.000000      2000.000000  2000.000000   \n",
       "mean         -0.009350       -0.009670        -0.010445    -0.057720   \n",
       "std           0.678188        0.454326         0.322362     2.100776   \n",
       "min          -3.730000       -2.010000        -1.170000    -6.780000   \n",
       "25%          -0.420000       -0.290000        -0.220000    -1.480000   \n",
       "50%           0.010000        0.010000         0.010000    -0.320000   \n",
       "75%           0.420000        0.290000         0.210000     1.140000   \n",
       "max           2.760000        1.710000         1.060000     6.570000   \n",
       "\n",
       "        <Yellow 5>     <Blue 5>    <DBlue 5>      <Red 1>   <Yellow 1>  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean     -0.195240    -0.469265     0.003965     0.001355     0.005170   \n",
       "std       5.273686     9.576264     4.601332     0.960603     2.270821   \n",
       "min     -12.670000   -22.460000   -15.400000    -4.060000    -7.840000   \n",
       "25%      -3.762500    -6.852500    -2.862500    -0.570000    -1.322500   \n",
       "50%      -0.415000    -0.855000     0.030000    -0.010000    -0.110000   \n",
       "75%       2.932500     4.762500     2.940000     0.530000     1.210000   \n",
       "max      19.070000    31.840000    13.530000     5.310000     9.490000   \n",
       "\n",
       "          <Blue 1>    <DBlue 1>      <SlowK>      <SlowD>  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean     -0.025220     0.001280    51.594990    51.572320  \n",
       "std       3.854396     2.197141    29.188785    28.361945  \n",
       "min     -12.680000   -10.240000     1.290000     2.420000  \n",
       "25%      -2.480000    -1.210000    23.612500    24.557500  \n",
       "50%      -0.260000    -0.030000    53.930000    53.715000  \n",
       "75%       2.182500     1.252500    78.162500    77.615000  \n",
       "max      13.800000     8.360000    99.050000    98.700000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw_mean = x_train_raw.mean()\n",
    "x_train_raw_sd = x_train_raw.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train_raw - x_train_raw_mean) / x_train_raw_sd\n",
    "x_test = (x_test_raw - x_train_raw_mean) / x_train_raw_sd\n",
    "\n",
    "# train and test data after standard scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "def switch(x):\n",
    "    return x * (1 / (1 + tf.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_log = \"CL_dnn_tf_log\"\n",
    "logdir = \"{}/run-{}/\".format(root_log, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# make sure that no node been made twice\n",
    "\n",
    "n_inputs = 18\n",
    "n_hidden1 = 200\n",
    "n_hidden2 = 150\n",
    "n_hidden3 = 100\n",
    "n_output = 1\n",
    "\n",
    "batch_norm_momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = (None), name = \"Y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5\n",
    "x_drop = tf.layers.dropout(x, dropout_rate, training = training)\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    batch_norm = partial(tf.layers.batch_normalization, training = training, momentum = batch_norm_momentum)\n",
    "    dense_layer = partial(tf.layers.dense, kernel_initializer = he_init)\n",
    "    \n",
    "    hidden1 = dense_layer(x_drop, n_hidden1, name = \"hidden1\")\n",
    "    bNorm1 = switch(batch_norm(hidden1))\n",
    "    hidden1_drop = tf.layers.dropout(bNorm1,dropout_rate, training = training)\n",
    "    \n",
    "    hidden2 = dense_layer(hidden1_drop, n_hidden2, name = \"hidden2\")\n",
    "    bNorm2 = switch(batch_norm(hidden2))\n",
    "    hidden2_drop = tf.layers.dropout(bNorm2,dropout_rate, training = training)\n",
    "    \n",
    "    hidden3 = dense_layer(hidden2_drop, n_hidden3, activation = switch, kernel_initializer = he_init, name = \"hidden3\")\n",
    "    bNorm3 = switch(batch_norm(hidden3))\n",
    "    hidden3_drop = tf.layers.dropout(bNorm3,dropout_rate, training = training)\n",
    "    \n",
    "    output = tf.layers.dense(hidden3_drop, n_output, activation = None, name = \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "注意上面 dense 裡前兩個參數的填寫方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"MSE\"):\n",
    "    error = output - y\n",
    "    mse = tf.reduce_mean(tf.square(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "mse_summary = tf.summary.scalar('mse', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.64127\n",
      "Epoch 100 MSE = 1.94588\n",
      "Epoch 200 MSE = 1.93888\n",
      "Epoch 300 MSE = 1.93317\n",
      "Epoch 400 MSE = 1.92169\n",
      "Epoch 500 MSE = 1.91976\n",
      "Epoch 600 MSE = 1.91211\n",
      "Epoch 700 MSE = 1.90151\n",
      "Epoch 800 MSE = 1.90434\n",
      "Epoch 900 MSE = 1.89635\n",
      "Final train mse =  1.90066\n",
      "Final test mse =  0.640801\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            current_mse = mse_summary.eval(feed_dict={x: x_train, y: y_train})\n",
    "            file_writer.add_summary(current_mse, epoch)\n",
    "            \n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={x: x_train, y: y_train}))\n",
    "            \n",
    "            save_path = saver.save(sess, \"./CL_dnn_save/temple_sample_model.ckpt\")\n",
    "        \n",
    "        sess.run([training_op, extra_update_ops], feed_dict={training: True, x: x_train, y: y_train})\n",
    "        \n",
    "   \n",
    "    CL_dnn_train_mse = mse.eval(feed_dict={x: x_train, y: y_train})\n",
    "    CL_dnn_train_error = error.eval(feed_dict={x: x_train, y: y_train})\n",
    "    \n",
    "    CL_dnn_test_mse = mse.eval(feed_dict={x: x_test, y: y_test})\n",
    "    CL_dnn_test_error = error.eval(feed_dict={x: x_test, y: y_test})\n",
    "    \n",
    "    print(\"Final train mse = \", CL_dnn_train_mse)\n",
    "    print(\"Final test mse = \", CL_dnn_test_mse)\n",
    "\n",
    "    final_save_path = saver.save(sess, \"./CL_dnn_save/final_sample_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37739\n",
      "0.795958\n"
     ]
    }
   ],
   "source": [
    "print(CL_dnn_train_error.std())\n",
    "print(CL_dnn_test_error.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'hidden3/kernel:0',\n",
       " 'hidden3/bias:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0',\n",
       " 'output/kernel:0',\n",
       " 'output/bias:0',\n",
       " 'train/beta1_power:0',\n",
       " 'train/beta2_power:0',\n",
       " 'hidden1/kernel/Adam:0',\n",
       " 'hidden1/kernel/Adam_1:0',\n",
       " 'hidden1/bias/Adam:0',\n",
       " 'hidden1/bias/Adam_1:0',\n",
       " 'batch_normalization/beta/Adam:0',\n",
       " 'batch_normalization/beta/Adam_1:0',\n",
       " 'batch_normalization/gamma/Adam:0',\n",
       " 'batch_normalization/gamma/Adam_1:0',\n",
       " 'hidden2/kernel/Adam:0',\n",
       " 'hidden2/kernel/Adam_1:0',\n",
       " 'hidden2/bias/Adam:0',\n",
       " 'hidden2/bias/Adam_1:0',\n",
       " 'batch_normalization_1/beta/Adam:0',\n",
       " 'batch_normalization_1/beta/Adam_1:0',\n",
       " 'batch_normalization_1/gamma/Adam:0',\n",
       " 'batch_normalization_1/gamma/Adam_1:0',\n",
       " 'hidden3/kernel/Adam:0',\n",
       " 'hidden3/kernel/Adam_1:0',\n",
       " 'hidden3/bias/Adam:0',\n",
       " 'hidden3/bias/Adam_1:0',\n",
       " 'batch_normalization_2/beta/Adam:0',\n",
       " 'batch_normalization_2/beta/Adam_1:0',\n",
       " 'batch_normalization_2/gamma/Adam:0',\n",
       " 'batch_normalization_2/gamma/Adam_1:0',\n",
       " 'output/kernel/Adam:0',\n",
       " 'output/kernel/Adam_1:0',\n",
       " 'output/bias/Adam:0',\n",
       " 'output/bias/Adam_1:0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[variable.name for variable in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**** Using trained network: ****\n",
    "\n",
    "**** reuse the construct phase but change the excution phase ****\n",
    "\n",
    "x_to_predict = ......\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./CL_dnn_save/final_sample_model.ckpt\")\n",
    "    y_predict = output.eval(feed_dict={x: x_to_predict})\n",
    "    print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
